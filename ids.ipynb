{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn\n",
    "import io\n",
    "import random\n",
    "train_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Train.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Test.csv'\n",
    "\n",
    "\n",
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n",
    "\n",
    "\n",
    "df = pd.read_csv(train_url,header=None, names = col_names)\n",
    "\n",
    "df_test = pd.read_csv(test_url, header=None, names = col_names)\n",
    "\n",
    "print('Dimensions of the Training set:',df.shape)\n",
    "print('Dimensions of the Test set:',df_test.shape)\n",
    "df.head(5)\n",
    "print('Label distribution Training set:')\n",
    "print(df['label'].value_counts())\n",
    "print()\n",
    "print('Label distribution Test set:')\n",
    "print(df_test['label'].value_counts())\n",
    "**Step 1: Data preprocessing:**\n",
    "\n",
    "One-Hot-Encoding, tüm kategorik özellikleri ikili özelliklere dönüştürmek için kullanılır. One-Hot-Endcoding gereksinimi, bu transformatöre giriş, kategorik(ayrık) özelliklerle alınan değerleri ifade eden bir tam sayı matrisi olmalıdır. Çıktı, her bir sütunun olası bir değere karşılık geldiği seyrek bir matris olacaktır. Giriş özelliklerinin [0, n_values] aralığında değerler aldıkları varsayılmaktadır. Bu nedenle her kategoriyi bir sayıya dönüştürmek için özelliklerin öncelikle LabelEncoder ile dönüştürülmesi gerekir.\n",
    "# sütunlar kategorik, henüz binary değil: protocol_type (column 2), service (column 3), flag (column 4).\n",
    "\n",
    "print('Training set:')\n",
    "for col_name in df.columns:\n",
    "    if df[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "print()\n",
    "print('Distribution of categories in service:')\n",
    "print(df['service'].value_counts().sort_values(ascending=False).head())\n",
    "# Test set\n",
    "print('Test set:')\n",
    "for col_name in df_test.columns:\n",
    "    if df_test[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df_test[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "**LabelEncoder**\n",
    "\n",
    "**Insert categorical features into a 2D numpy array**\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "categorical_columns=['protocol_type', 'service', 'flag']\n",
    "\n",
    "df_categorical_values = df[categorical_columns]\n",
    "testdf_categorical_values = df_test[categorical_columns]\n",
    "\n",
    "df_categorical_values.head()\n",
    "# protocol type\n",
    "unique_protocol=sorted(df.protocol_type.unique())\n",
    "string1 = 'Protocol_type_'\n",
    "unique_protocol2=[string1 + x for x in unique_protocol]\n",
    "print(unique_protocol2)\n",
    "\n",
    "# service\n",
    "unique_service=sorted(df.service.unique())\n",
    "string2 = 'service_'\n",
    "unique_service2=[string2 + x for x in unique_service]\n",
    "print(unique_service2)\n",
    "\n",
    "\n",
    "# flag\n",
    "unique_flag=sorted(df.flag.unique())\n",
    "string3 = 'flag_'\n",
    "unique_flag2=[string3 + x for x in unique_flag]\n",
    "print(unique_flag2)\n",
    "\n",
    "\n",
    "# put together\n",
    "dumcols=unique_protocol2 + unique_service2 + unique_flag2\n",
    "\n",
    "\n",
    "#do it for test set\n",
    "unique_service_test=sorted(df_test.service.unique())\n",
    "unique_service2_test=[string2 + x for x in unique_service_test]\n",
    "testdumcols=unique_protocol2 + unique_service2_test + unique_flag2\n",
    "\n",
    "**Transform categorical features into numbers using LabelEncoder()**\n",
    "df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "print(df_categorical_values.head())\n",
    "print('--------------------')\n",
    "print(df_categorical_values_enc.head())\n",
    "\n",
    "# test set\n",
    "testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "**One-Hot-Encoding**\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "df_categorical_values_encenc = enc.fit_transform(df_categorical_values_enc)\n",
    "df_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(),columns=dumcols)\n",
    "\n",
    "\n",
    "# test set\n",
    "testdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\n",
    "testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)\n",
    "\n",
    "df_cat_data.head()\n",
    "**Test setteki eksik sütunlar eklenir**\n",
    "trainservice=df['service'].tolist()\n",
    "testservice= df_test['service'].tolist()\n",
    "difference=list(set(trainservice) - set(testservice))\n",
    "string = 'service_'\n",
    "difference=[string + x for x in difference]\n",
    "difference\n",
    "for col in difference:\n",
    "    testdf_cat_data[col] = 0\n",
    "\n",
    "print(df_cat_data.shape)    \n",
    "print(testdf_cat_data.shape)\n",
    "**Ana dataframe'e yeni sayısal sütunlar eklenir**\n",
    "newdf=df.join(df_cat_data)\n",
    "newdf.drop('flag', axis=1, inplace=True)\n",
    "newdf.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf.drop('service', axis=1, inplace=True)\n",
    "\n",
    "# test data\n",
    "newdf_test=df_test.join(testdf_cat_data)\n",
    "newdf_test.drop('flag', axis=1, inplace=True)\n",
    "newdf_test.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf_test.drop('service', axis=1, inplace=True)\n",
    "\n",
    "print(newdf.shape)\n",
    "print(newdf_test.shape)\n",
    " Dataset her atak kategorisi için ayrı datasetlere ayrıldı. Atak etiketleri her biri için yeniden adlandırıldı. 0=Normal, 1=DoS, 2=Probe, 3=R2L, 4=U2R. Yeni datasetlerde etiket sütunu yeni değerler ile değiştirildi.\n",
    " \n",
    " DoS : \n",
    " \n",
    " Probe : \n",
    " \n",
    " R2L :\n",
    " \n",
    " U2R :\n",
    "labeldf=newdf['label']\n",
    "labeldf_test=newdf_test['label']\n",
    "\n",
    "\n",
    "# change the label column\n",
    "newlabeldf=labeldf.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "newlabeldf_test=labeldf_test.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "\n",
    "\n",
    "\n",
    "# put the new label column back\n",
    "newdf['label'] = newlabeldf\n",
    "newdf_test['label'] = newlabeldf_test\n",
    "to_drop_DoS = [0,1]\n",
    "to_drop_Probe = [0,2]\n",
    "to_drop_R2L = [0,3]\n",
    "to_drop_U2R = [0,4]\n",
    "\n",
    "# Kendisi dışındaki label değerine sahip tüm satırları filtrele\n",
    "# isin filter function\n",
    "\n",
    "DoS_df=newdf[newdf['label'].isin(to_drop_DoS)];\n",
    "Probe_df=newdf[newdf['label'].isin(to_drop_Probe)];\n",
    "R2L_df=newdf[newdf['label'].isin(to_drop_R2L)];\n",
    "U2R_df=newdf[newdf['label'].isin(to_drop_U2R)];\n",
    "\n",
    "\n",
    "\n",
    "#test\n",
    "DoS_df_test=newdf_test[newdf_test['label'].isin(to_drop_DoS)];\n",
    "Probe_df_test=newdf_test[newdf_test['label'].isin(to_drop_Probe)];\n",
    "R2L_df_test=newdf_test[newdf_test['label'].isin(to_drop_R2L)];\n",
    "U2R_df_test=newdf_test[newdf_test['label'].isin(to_drop_U2R)];\n",
    "\n",
    "\n",
    "print('Train:')\n",
    "print('Dimensions of DoS:' ,DoS_df.shape)\n",
    "print('Dimensions of Probe:' ,Probe_df.shape)\n",
    "print('Dimensions of R2L:' ,R2L_df.shape)\n",
    "print('Dimensions of U2R:' ,U2R_df.shape)\n",
    "print()\n",
    "print('Test:')\n",
    "print('Dimensions of DoS:' ,DoS_df_test.shape)\n",
    "print('Dimensions of Probe:' ,Probe_df_test.shape)\n",
    "print('Dimensions of R2L:' ,R2L_df_test.shape)\n",
    "print('Dimensions of U2R:' ,U2R_df_test.shape)\n",
    "**Step 2: Feature Scaling**\n",
    "# Split dataframes into X & Y\n",
    "# X Özellikler , Y sonuç değişkenleri\n",
    "\n",
    "X_DoS = DoS_df.drop('label',1)\n",
    "Y_DoS = DoS_df.label\n",
    "\n",
    "X_Probe = Probe_df.drop('label',1)\n",
    "Y_Probe = Probe_df.label\n",
    "\n",
    "X_R2L = R2L_df.drop('label',1)\n",
    "Y_R2L = R2L_df.label\n",
    "\n",
    "X_U2R = U2R_df.drop('label',1)\n",
    "Y_U2R = U2R_df.label\n",
    "\n",
    "# test set\n",
    "X_DoS_test = DoS_df_test.drop('label',1)\n",
    "Y_DoS_test = DoS_df_test.label\n",
    "\n",
    "X_Probe_test = Probe_df_test.drop('label',1)\n",
    "Y_Probe_test = Probe_df_test.label\n",
    "\n",
    "X_R2L_test = R2L_df_test.drop('label',1)\n",
    "Y_R2L_test = R2L_df_test.label\n",
    "\n",
    "X_U2R_test = U2R_df_test.drop('label',1)\n",
    "Y_U2R_test = U2R_df_test.label\n",
    "\n",
    "**Sütun isimleri bu aşamada silineceği için daha sonra kullanmak üzere sütun isimlerini kayıt ederiz.**\n",
    "colNames=list(X_DoS)\n",
    "colNames_test=list(X_DoS_test)\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler1 = preprocessing.StandardScaler().fit(X_DoS)\n",
    "X_DoS=scaler1.transform(X_DoS) \n",
    "\n",
    "scaler2 = preprocessing.StandardScaler().fit(X_Probe)\n",
    "X_Probe=scaler2.transform(X_Probe)\n",
    "\n",
    "scaler3 = preprocessing.StandardScaler().fit(X_R2L)\n",
    "X_R2L=scaler3.transform(X_R2L)\n",
    "\n",
    "scaler4 = preprocessing.StandardScaler().fit(X_U2R)\n",
    "X_U2R=scaler4.transform(X_U2R) \n",
    "\n",
    "# test data\n",
    "scaler5 = preprocessing.StandardScaler().fit(X_DoS_test)\n",
    "X_DoS_test=scaler5.transform(X_DoS_test) \n",
    "\n",
    "scaler6 = preprocessing.StandardScaler().fit(X_Probe_test)\n",
    "X_Probe_test=scaler6.transform(X_Probe_test) \n",
    "\n",
    "scaler7 = preprocessing.StandardScaler().fit(X_R2L_test)\n",
    "X_R2L_test=scaler7.transform(X_R2L_test) \n",
    "\n",
    "scaler8 = preprocessing.StandardScaler().fit(X_U2R_test)\n",
    "X_U2R_test=scaler8.transform(X_U2R_test)\n",
    "**Step 3: Feature Selection:**\n",
    "\n",
    "---\n",
    "**Recursive Feature Elimination (RFE) , en iyi 13 özellik (grup olarak)**\n",
    "# Random Forest\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10,n_jobs=2)\n",
    "rfe = RFE(estimator=clf, n_features_to_select=13, step=1)\n",
    "\n",
    "rfe.fit(X_DoS, Y_DoS.astype(int))\n",
    "X_rfeDoS=rfe.transform(X_DoS)\n",
    "true=rfe.support_\n",
    "rfecolindex_DoS=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_DoS=list(colNames[i] for i in rfecolindex_DoS)\n",
    "rfe.fit(X_Probe, Y_Probe.astype(int))\n",
    "X_rfeProbe=rfe.transform(X_Probe)\n",
    "true=rfe.support_\n",
    "rfecolindex_Probe=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_Probe=list(colNames[i] for i in rfecolindex_Probe)\n",
    "\n",
    "rfe.fit(X_R2L, Y_R2L.astype(int))\n",
    "X_rfeR2L=rfe.transform(X_R2L)\n",
    "true=rfe.support_\n",
    "rfecolindex_R2L=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_R2L=list(colNames[i] for i in rfecolindex_R2L)\n",
    "rfe.fit(X_U2R, Y_U2R.astype(int))\n",
    "X_rfeU2R=rfe.transform(X_U2R)\n",
    "true=rfe.support_\n",
    "rfecolindex_U2R=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_U2R=list(colNames[i] for i in rfecolindex_U2R)\n",
    "**Summary of features selected by RFE**\n",
    "print('Features selected for DoS:',rfecolname_DoS)\n",
    "print()\n",
    "print('Features selected for Probe:',rfecolname_Probe)\n",
    "print()\n",
    "print('Features selected for R2L:',rfecolname_R2L)\n",
    "print()\n",
    "print('Features selected for U2R:',rfecolname_U2R)\n",
    "\n",
    "print(X_rfeDoS.shape)\n",
    "print(X_rfeProbe.shape)\n",
    "print(X_rfeR2L.shape)\n",
    "print(X_rfeU2R.shape)\n",
    "\n",
    "**Step 4: Build the model:**\n",
    "\n",
    "Classifier is trained for all features and for reduced features, for later comparison.\n",
    "\n",
    "The classifier model itself is stored in the clf variable.\n",
    "# all features\n",
    "clf_DoS=RandomForestClassifier(n_estimators=10,n_jobs=2)\n",
    "clf_Probe=RandomForestClassifier(n_estimators=10,n_jobs=2)\n",
    "clf_R2L=RandomForestClassifier(n_estimators=10,n_jobs=2)\n",
    "clf_U2R=RandomForestClassifier(n_estimators=10,n_jobs=2)\n",
    "clf_DoS.fit(X_DoS, Y_DoS.astype(int))\n",
    "clf_Probe.fit(X_Probe, Y_Probe.astype(int))\n",
    "clf_R2L.fit(X_R2L, Y_R2L.astype(int))\n",
    "clf_U2R.fit(X_U2R, Y_U2R.astype(int))\n",
    "# selected features\n",
    "clf_rfeDoS=RandomForestClassifier(n_estimators=10,n_jobs=2)\n",
    "clf_rfeProbe=RandomForestClassifier(n_estimators=10,n_jobs=2)\n",
    "clf_rfeR2L=RandomForestClassifier(n_estimators=10,n_jobs=2)\n",
    "clf_rfeU2R=RandomForestClassifier(n_estimators=10,n_jobs=2)\n",
    "clf_rfeDoS.fit(X_rfeDoS, Y_DoS.astype(int))\n",
    "clf_rfeProbe.fit(X_rfeProbe, Y_Probe.astype(int))\n",
    "clf_rfeR2L.fit(X_rfeR2L, Y_R2L.astype(int))\n",
    "clf_rfeU2R.fit(X_rfeU2R, Y_U2R.astype(int))\n",
    "**Step 5: Prediction & Evaluation (validation):**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Using all Features for each category\n",
    "\n",
    "Confusion Matrices\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "DoS¶\n",
    "# Apply the classifier we trained to the test data (which it has never seen before)\n",
    "clf_DoS.predict(X_DoS_test)\n",
    "\n",
    "# View the predicted probabilities of the first 10 observations\n",
    "clf_DoS.predict_proba(X_DoS_test)[0:10]\n",
    "Y_DoS_pred=clf_DoS.predict(X_DoS_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_DoS_test, Y_DoS_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**Probe**\n",
    "Y_Probe_pred=clf_Probe.predict(X_Probe_test)\n",
    "# Create confusion matrix\n",
    "\n",
    "pd.crosstab(Y_Probe_test, Y_Probe_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**R2L**\n",
    "Y_R2L_pred=clf_R2L.predict(X_R2L_test)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_R2L_test, Y_R2L_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**U2R**\n",
    "Y_U2R_pred=clf_U2R.predict(X_U2R_test)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_U2R_test, Y_U2R_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**Cross Validation: Accuracy, Precision, Recall, F-measure**\n",
    "**DoS**\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "accuracy = cross_val_score(clf_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='precision')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='recall')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='f1')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "\n",
    "**Probe**\n",
    "accuracy = cross_val_score(clf_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**U2R**\n",
    "accuracy = cross_val_score(clf_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "\n",
    "**R2L**\n",
    "accuracy = cross_val_score(clf_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**Using 13 Features for each category**\n",
    "\n",
    "\n",
    "Confusion Matrices\n",
    "\n",
    "DoS\n",
    "# reduce test dataset to 13 features, use only features described in rfecolname_DoS etc.\n",
    "X_DoS_test2=X_DoS_test[:,rfecolindex_DoS]\n",
    "X_Probe_test2=X_Probe_test[:,rfecolindex_Probe]\n",
    "X_R2L_test2=X_R2L_test[:,rfecolindex_R2L]\n",
    "X_U2R_test2=X_U2R_test[:,rfecolindex_U2R]\n",
    "X_U2R_test2.shape\n",
    "Y_DoS_pred2=clf_rfeDoS.predict(X_DoS_test2)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_DoS_test, Y_DoS_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**Probe**\n",
    "Y_Probe_pred2=clf_rfeProbe.predict(X_Probe_test2)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_Probe_test, Y_Probe_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "\n",
    "**R2L**\n",
    "Y_R2L_pred2=clf_rfeR2L.predict(X_R2L_test2)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_R2L_test, Y_R2L_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "\n",
    "**U2R**\n",
    "Y_U2R_pred2=clf_rfeU2R.predict(X_U2R_test2)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_U2R_test, Y_U2R_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**Cross Validation: Accuracy, Precision, Recall, F-measure**\n",
    "\n",
    "**DoS**\n",
    "\n",
    "accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='precision')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='recall')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='f1')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**Probe**\n",
    "accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "\n",
    "**R2L**\n",
    "accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**U2R**\n",
    "accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "# KNeighbors\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_KNN_DoS=KNeighborsClassifier()\n",
    "clf_KNN_Probe=KNeighborsClassifier()\n",
    "clf_KNN_R2L=KNeighborsClassifier()\n",
    "clf_KNN_U2R=KNeighborsClassifier()\n",
    "\n",
    "clf_KNN_DoS.fit(X_DoS, Y_DoS.astype(int))\n",
    "clf_KNN_Probe.fit(X_Probe, Y_Probe.astype(int))\n",
    "clf_KNN_R2L.fit(X_R2L, Y_R2L.astype(int))\n",
    "clf_KNN_U2R.fit(X_U2R, Y_U2R.astype(int))\n",
    "\n",
    " **DoS**\n",
    "Y_DoS_pred=clf_KNN_DoS.predict(X_DoS_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_DoS_test, Y_DoS_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**Probe**\n",
    "Y_Probe_pred=clf_KNN_Probe.predict(X_Probe_test)\n",
    "# Create confusion matrix\n",
    "\n",
    "pd.crosstab(Y_Probe_test, Y_Probe_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**R2L**\n",
    "Y_R2L_pred=clf_KNN_R2L.predict(X_R2L_test)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_R2L_test, Y_R2L_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**U2R**\n",
    "Y_U2R_pred=clf_KNN_U2R.predict(X_U2R_test)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_U2R_test, Y_U2R_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**Cross Validation: Accuracy, Precision, Recall, F-measure**\n",
    "**DoS**\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "accuracy = cross_val_score(clf_KNN_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_KNN_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='precision')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_KNN_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='recall')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_KNN_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='f1')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**Probe**\n",
    "accuracy = cross_val_score(clf_KNN_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_KNN_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_KNN_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_KNN_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**R2L**\n",
    "accuracy = cross_val_score(clf_KNN_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_KNN_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_KNN_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_KNN_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**U2R**\n",
    "accuracy = cross_val_score(clf_KNN_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_KNN_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_KNN_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_KNN_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "\n",
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_SVM_DoS=SVC(kernel='linear', C=1.0, random_state=0)\n",
    "clf_SVM_Probe=SVC(kernel='linear', C=1.0, random_state=0)\n",
    "clf_SVM_R2L=SVC(kernel='linear', C=1.0, random_state=0)\n",
    "clf_SVM_U2R=SVC(kernel='linear', C=1.0, random_state=0)\n",
    "\n",
    "clf_SVM_DoS.fit(X_DoS, Y_DoS.astype(int))\n",
    "clf_SVM_Probe.fit(X_Probe, Y_Probe.astype(int))\n",
    "clf_SVM_R2L.fit(X_R2L, Y_R2L.astype(int))\n",
    "clf_SVM_U2R.fit(X_U2R, Y_U2R.astype(int))\n",
    "**DoS**\n",
    "Y_DoS_pred=clf_SVM_DoS.predict(X_DoS_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_DoS_test, Y_DoS_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "Y_Probe_pred=clf_SVM_Probe.predict(X_Probe_test)\n",
    "# Create confusion matrix\n",
    "\n",
    "pd.crosstab(Y_Probe_test, Y_Probe_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "Y_R2L_pred=clf_SVM_R2L.predict(X_R2L_test)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_R2L_test, Y_R2L_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "Y_U2R_pred=clf_SVM_U2R.predict(X_U2R_test)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_U2R_test, Y_U2R_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**DoS**\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "accuracy = cross_val_score(clf_SVM_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_SVM_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='precision')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_SVM_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='recall')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_SVM_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='f1')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**Probe**\n",
    "accuracy = cross_val_score(clf_SVM_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_SVM_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_SVM_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_SVM_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**R2L**\n",
    "accuracy = cross_val_score(clf_SVM_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_SVM_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_SVM_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_SVM_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**U2R**\n",
    "accuracy = cross_val_score(clf_SVM_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_SVM_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_SVM_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_SVM_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "# Ensemble Learning\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf_voting_DoS = VotingClassifier(estimators=[('rf', clf_DoS), ('knn', clf_KNN_DoS), ('svm', clf_SVM_DoS)], voting='hard')\n",
    "clf_voting_Probe = VotingClassifier(estimators=[('rf', clf_Probe), ('knn', clf_KNN_Probe), ('svm', clf_SVM_Probe)], voting='hard')\n",
    "clf_voting_R2L = VotingClassifier(estimators=[('rf', clf_R2L), ('knn', clf_KNN_R2L), ('svm', clf_SVM_R2L)], voting='hard')\n",
    "clf_voting_U2R = VotingClassifier(estimators=[('rf', clf_U2R), ('knn', clf_KNN_U2R), ('svm', clf_SVM_U2R)], voting='hard')\n",
    "\n",
    "clf_voting_DoS.fit(X_DoS, Y_DoS.astype(int))\n",
    "clf_voting_Probe.fit(X_Probe, Y_Probe.astype(int))\n",
    "clf_voting_R2L.fit(X_R2L, Y_R2L.astype(int))\n",
    "clf_voting_U2R.fit(X_U2R, Y_U2R.astype(int))\n",
    "\n",
    "**DoS**\n",
    "Y_DoS_pred=clf_voting_DoS.predict(X_DoS_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_DoS_test, Y_DoS_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**Probe**\n",
    "Y_Probe_pred=clf_voting_Probe.predict(X_Probe_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_Probe_test, Y_Probe_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**R2L**\n",
    "Y_R2L_pred=clf_voting_R2L.predict(X_R2L_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_R2L_test, Y_R2L_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**U2R**\n",
    "Y_U2R_pred=clf_voting_U2R.predict(X_U2R_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_U2R_test, Y_U2R_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "**DoS**\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "accuracy = cross_val_score(clf_voting_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_voting_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='precision')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_voting_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='recall')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_voting_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='f1')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**Probe**\n",
    "accuracy = cross_val_score(clf_voting_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_voting_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_voting_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_voting_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-mesaure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**R2L**\n",
    "accuracy = cross_val_score(clf_voting_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_voting_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_voting_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_voting_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))\n",
    "**U2R**\n",
    "accuracy = cross_val_score(clf_voting_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_voting_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_voting_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_voting_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
